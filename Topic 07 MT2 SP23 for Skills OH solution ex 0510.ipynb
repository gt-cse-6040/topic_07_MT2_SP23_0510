{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gt-cse-6040/topic_07_MT2_SP23_0510/blob/main/Topic%2007%20MT2%20SP23%20for%20Skills%20OH%20solution%20ex%200510.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d825be40",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "tags": [
          "notebook_header"
        ],
        "id": "d825be40"
      },
      "source": [
        "# Midterm 2, Spring 2023: Better Reads\n",
        "\n",
        "_Version history:_\n",
        "- 1.0.1 (Sun Apr 2): Corrected typo in Ex. 7 demo\n",
        "- 1.0: Initial release\n",
        "\n",
        "*All of the header information is important. Please read it.*\n",
        "\n",
        "**Topics, number of exercises:** This problem builds on your knowledge of Numpy, pandas, database organization, graph abstractions, and basic Python (for interfacing with other Python libraries). It has **11** exercises, numbered 0 to **10**. There are **21** available points. However, to earn 100% the threshold is **12** points. (Therefore, once you hit **12** points, you can stop. There is no extra credit for exceeding this threshold.)\n",
        "\n",
        "**Free points!** This exam includes one exercise, Exercise 3, whose points are \"**free**.\" However, to get these points you need to read some text and _submit the notebook to the autograder at least once_.\n",
        "\n",
        "**Exercise ordering:** Each exercise builds logically on previous exercises, but you may solve them in any order. Exercises are **not** necessarily ordered by difficulty, but higher point values usually imply more difficult tasks.\n",
        "\n",
        "**Demo cells:** Code cells that start with the comment `### define demo inputs` will load results from prior exercises applied to the entire data set and use those to build demo inputs. These must be run for later demos to work properly but they do not affect the test cells. The data loaded by these cells may be large (at least in terms of human readability). You are free to inspect them, but we did not print them in the starter code.\n",
        "\n",
        "**Debugging you code:** Right before each exercise test cell, there is a block of text explaining the variables available to you for debugging. You may use these to test your code and can print/display them as needed (careful when printing large objects, you may want to print the head or chunks of rows at a time).\n",
        "\n",
        "**Exercise point breakdown:**\n",
        "\n",
        "- Exercise 0: **2** points\n",
        "- Exercise 1: **1** point\n",
        "- Exercise 2: **3** points\n",
        "- Exercise 3: **2** point **FREEBIE! Submit to record them**\n",
        "- Exercise 4: **1** point\n",
        "- Exercise 5: **2** points\n",
        "- Exercise 6: **2** points\n",
        "- Exercise 7: **1** point\n",
        "- Exercise 8: **3** points\n",
        "- Exercise 9: **2** points\n",
        "- Exercise 10: **2** points\n",
        "\n",
        "**Final reminders:**\n",
        "\n",
        "- Submit after **every exercise**\n",
        "- Review the generated grade report after you submit to see what errors were returned\n",
        "- Stay calm, skip problems as needed, and take short breaks at your leisure"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6019d2b8",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "tags": [
          "topic_intro"
        ],
        "id": "6019d2b8"
      },
      "source": [
        "# Background: Better Reads #\n",
        "\n",
        "[Goodreads](https://www.goodreads.com/) is a website devoted to curating user-generated book reviews. You'll do some elementary data-mining to uncover \"communities\" of users who like the same books. Such insights might help users find like-minded communities and generate better book recommendations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fd80f0b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-29T13:30:23.592700Z",
          "start_time": "2023-03-29T13:30:23.585568Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "2fd80f0b"
      },
      "source": [
        "**Overall workflow.** This notebook has six (6) parts with about 1-3 exercises each.\n",
        "* **Part A:** Analyze user-book interactions [SQL, pandas]\n",
        "* **Part B:** Power-law analysis [pandas, Numpy]\n",
        "* **Part C:** Edge lists, NetworkX, and graph clusters [Python, graphs]\n",
        "* **Part D:** Finding communities via graph clustering [SQL, pandas]\n",
        "* **Part E:** Identifying \"top reads\" by community [pandas]\n",
        "* **Part F:** Merging inventory metadata [pandas]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e24f7633",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "e24f7633"
      },
      "source": [
        "# Getting started (modules) #\n",
        "\n",
        "Skim the code cell below and then run it. Take note of the standard preloaded modules, `numpy as np`, `pandas as pd`, and `sqlite3 as db`, any or all of which you may need to construct your solutions.\n",
        "\n",
        "The other functions are used by our demo and testing code. You can ignore them unless an exercise asks you to do otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef8bad2d",
      "metadata": {
        "id": "ef8bad2d"
      },
      "outputs": [],
      "source": [
        "# uncomment in Google Colab\n",
        "# !python --version\n",
        "!pip install dill\n",
        "import dill as pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6c8b8a5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:11.441029Z",
          "start_time": "2023-03-30T22:24:11.074402Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "tags": [
          "global_imports"
        ],
        "id": "e6c8b8a5"
      },
      "outputs": [],
      "source": [
        "### Global Imports\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# Standard Python modules\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sqlite3 as db\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a75c3f3",
      "metadata": {
        "id": "7a75c3f3"
      },
      "outputs": [],
      "source": [
        "### Global Imports\n",
        "# Some functionality needed by the notebook and demo cells:\n",
        "from pprint import pprint, pformat\n",
        "import math\n",
        "\n",
        "# === Iteration === #\n",
        "\n",
        "def isiter(x):\n",
        "    \"\"\"\n",
        "    Returns `True` if `x` is iterable.\n",
        "\n",
        "    Uses the \"duck typing\" method described here:\n",
        "    https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable\n",
        "    \"\"\"\n",
        "    try:\n",
        "        iterator = iter(x)\n",
        "    except TypeError:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def sample_iter(I, n=1, rng_or_seed=None, replace=False, safe=True):\n",
        "    from pandas import DataFrame\n",
        "    from numpy import ndarray, array\n",
        "\n",
        "    rng = get_rng(rng_or_seed, ret_type=False)\n",
        "    n_sample = min(n, len(I)) if safe else n\n",
        "    sample_locs = rng.choice(range(len(I)), size=n_sample, replace=replace)\n",
        "    if isinstance(I, DataFrame):\n",
        "        sample = I.iloc[sample_locs]\n",
        "    elif isinstance(I, ndarray) or isinstance(I, list):\n",
        "        sample = I[sample_locs]\n",
        "    elif isinstance(I, dict):\n",
        "        sample_values = list(I.keys())[sample_locs]\n",
        "        sample = {k: I[k] for k in sample_values}\n",
        "    else:\n",
        "        J = array(list(I))\n",
        "        sample = type(I)(J[sample_locs])\n",
        "    return sample\n",
        "\n",
        "# === Messages === #\n",
        "\n",
        "def status_msg(s, verbose=True, **kwargs):\n",
        "    if verbose:\n",
        "        print(s, **kwargs)\n",
        "\n",
        "# === pandas ===\n",
        "\n",
        "def subselect(df, col, values):\n",
        "    \"\"\"\n",
        "    Subselects rows of a `DataFrame` where the column `col`\n",
        "    contains any of the given `values`.\n",
        "\n",
        "    If `values` is a non-iterable object _or_ a `str`,\n",
        "    then this function treats it as a single value to\n",
        "    find.\n",
        "    \"\"\"\n",
        "    if not isinstance(values, str) and isiter(values):\n",
        "        return df[df[col].isin(values)]\n",
        "    return df[df[col] == values]\n",
        "\n",
        "# === Input/output === #\n",
        "\n",
        "# def text_to_file(s, basename, dirname='resource/asnlib/publicdata/', overwrite=True, verbose=True):\n",
        "def text_to_file(s, basename, dirname='', overwrite=True, verbose=True):\n",
        "    from os.path import isfile\n",
        "    filename = f\"{dirname}{basename}\"\n",
        "    status_msg(f\"Writing string to '{filename}'...\", verbose=verbose)\n",
        "    if not overwrite and isfile(filename):\n",
        "        status_msg(f\"  ==> File exists already; skipping.\", verbose=verbose)\n",
        "    else:\n",
        "        with open(filename, \"wt\") as fp:\n",
        "            fp.write(s)\n",
        "        status_msg(f\"  ==> Done!\", verbose=verbose)\n",
        "\n",
        "# def load_text_from_file(basename, dirname='resource/asnlib/publicdata/', abort_on_error=False, verbose=False):\n",
        "def load_text_from_file(basename, dirname='', abort_on_error=False, verbose=False):\n",
        "    from os.path import isfile\n",
        "    filename = f\"{dirname}{basename}\"\n",
        "    status_msg(f\"Loading string from '{filename}'...\", verbose=verbose)\n",
        "    if isfile(filename):\n",
        "        try:\n",
        "            with open(filename, \"rt\") as fp:\n",
        "                s = fp.read()\n",
        "            status_msg(f\"  ==> Done!\", verbose=verbose)\n",
        "        except:\n",
        "            if abort_on_error:\n",
        "                raise\n",
        "            else:\n",
        "                status_msg(f\"  ==> An error occurred.\", verbose=verbose)\n",
        "                s = ''\n",
        "    return s\n",
        "\n",
        "# def df_to_file(df, basename, dirname='resource/asnlib/publicdata/', overwrite=True, verbose=True):\n",
        "def df_to_file(df, basename, dirname='', overwrite=True, verbose=True):\n",
        "    from os.path import isfile\n",
        "    from dill import dumps\n",
        "    filename = f\"{dirname}{basename}\"\n",
        "    if verbose:\n",
        "        print(f\"Writing `DataFrame` to '{filename}'...\")\n",
        "    if not overwrite and isfile(filename):\n",
        "        print(f\"  ==> File exists already; skipping.\")\n",
        "    else:\n",
        "        with open(filename, \"wb\") as fp:\n",
        "            fp.write(dumps(df))\n",
        "        print(f\"  ==> Done!\")\n",
        "\n",
        "# def load_df_from_file(basename, dirname='resource/asnlib/publicdata/', abort_on_error=False, verbose=False):\n",
        "def load_df_from_file(basename, dirname='', abort_on_error=False, verbose=False):\n",
        "    from os.path import isfile\n",
        "    from dill import loads\n",
        "    from pandas import DataFrame\n",
        "    df = DataFrame()\n",
        "    filename = f\"{dirname}{basename}\"\n",
        "    status_msg(f\"Loading `DataFrame` from '{filename}'...\", verbose=verbose)\n",
        "    if isfile(filename):\n",
        "        try:\n",
        "            with open(filename, \"rb\") as fp:\n",
        "                df = loads(fp.read())\n",
        "            status_msg(f\"  ==> Done!\", verbose=verbose)\n",
        "        except:\n",
        "            if abort_on_error:\n",
        "                raise\n",
        "            else:\n",
        "                df = DataFrame()\n",
        "                status_msg(f\"  ==> An error occurred.\", verbose=verbose)\n",
        "    return df\n",
        "\n",
        "# def obj_to_file(df, basename, dirname='resource/asnlib/publicdata/', overwrite=True, verbose=True):\n",
        "def obj_to_file(df, basename, dirname='', overwrite=True, verbose=True):\n",
        "    from os.path import isfile\n",
        "    from dill import dumps\n",
        "    filename = f\"{dirname}{basename}\"\n",
        "    if verbose:\n",
        "        print(f\"Writing object (type `{type(df)}`) to '{filename}'...\")\n",
        "    if not overwrite and isfile(filename):\n",
        "        print(f\"  ==> File exists already; skipping.\")\n",
        "    else:\n",
        "        with open(filename, \"wb\") as fp:\n",
        "            fp.write(dumps(df))\n",
        "        print(f\"  ==> Done!\")\n",
        "\n",
        "# def load_obj_from_file(basename, dirname='resource/asnlib/publicdata/', abort_on_error=False, verbose=False):\n",
        "def load_obj_from_file(basename, dirname='', abort_on_error=False, verbose=False):\n",
        "    from os.path import isfile\n",
        "    from dill import loads\n",
        "    from pandas import DataFrame\n",
        "    filename = f\"{dirname}{basename}\"\n",
        "    status_msg(f\"Loading object from '{filename}'...\", verbose=verbose)\n",
        "    if isfile(filename):\n",
        "        try:\n",
        "            with open(filename, \"rb\") as fp:\n",
        "                df = loads(fp.read())\n",
        "            status_msg(f\"  ==> Done! Type: `{type(df)}`\", verbose=verbose)\n",
        "        except:\n",
        "            if abort_on_error:\n",
        "                raise\n",
        "            else:\n",
        "                df = DataFrame()\n",
        "                status_msg(f\"  ==> An error occurred.\", verbose=verbose)\n",
        "    else:\n",
        "        df = None\n",
        "    return df\n",
        "\n",
        "# def load_table_from_db(table_name, basename, dirname=\"resource/asnlib/publicdata/\", verbose=False):\n",
        "def load_table_from_db(table_name, basename, dirname=\"\", verbose=False):\n",
        "    from sqlite3 import connect\n",
        "    from pandas import read_sql\n",
        "    filename = f\"{dirname}{basename}\"\n",
        "    if verbose:\n",
        "        print(f\"Retrieving table `{table_name}` from SQLite3 DB `{filename}`...\")\n",
        "    conn = connect(f\"file:{filename}?mode=ro\", uri=True)\n",
        "    df = read_sql(f\"SELECT * FROM {table_name}\", conn)\n",
        "    conn.close()\n",
        "    if verbose:\n",
        "        print(f\"... done! Found {len(df)} rows.\")\n",
        "    return df\n",
        "\n",
        "# ==== RNGs ==== #\n",
        "\n",
        "# https://stackoverflow.com/questions/279561/what-is-the-python-equivalent-of-static-variables-inside-a-function\n",
        "def static_vars(**kwargs):\n",
        "    def decorate(func):\n",
        "        for k in kwargs:\n",
        "            setattr(func, k, kwargs[k])\n",
        "        return func\n",
        "    return decorate\n",
        "\n",
        "@static_vars(DEFAULT_RNG=None)\n",
        "def get_rng(rng_or_seed, ret_type=True):\n",
        "    \"\"\"\n",
        "    Returns a valid pseudorandom-number generator (RNG) object\n",
        "    based on how `rng_or_seed` is set:\n",
        "\n",
        "    - An integer: Creates a new RNG with the integer as a seed\n",
        "    - An existing RNG object: Returns the same object\n",
        "    - `None`: Returns a global \"default\" RNG, which is created\n",
        "      once at module initialization time.\n",
        "\n",
        "    If `ret_type` is set, this function also returns a descriptive\n",
        "    string saying which of the above cases applies. (The intent of\n",
        "    this string is for use in printing as part of debugging output.)\n",
        "    \"\"\"\n",
        "    # Initialize static variable, DEFAULT_RNG\n",
        "    from numpy.random import default_rng\n",
        "    if get_rng.DEFAULT_RNG is None:\n",
        "        get_rng.DEFAULT_RNG = default_rng(1_234_567_890)\n",
        "\n",
        "    if isinstance(rng_or_seed, int):\n",
        "        rng = default_rng(rng_or_seed)\n",
        "        rng_type = f'`default_rng({rng_or_seed})`'\n",
        "    elif rng_or_seed is None:\n",
        "        rng = get_rng.DEFAULT_RNG\n",
        "        rng_type = f'`DEFAULT_RNG` [{rng}]'\n",
        "    else:\n",
        "        rng = rng_or_seed # had better be a RNG\n",
        "        rng_type = f'User-supplied [{rng}]'\n",
        "\n",
        "    return (rng, rng_type) if ret_type else rng\n",
        "\n",
        "# ==== Plotting ==== #\n",
        "def plot_series_loglog(series, ax=None, figsize=(8, 8/16*9), **kwargs):\n",
        "    from matplotlib.pyplot import figure, gca\n",
        "    if ax is None:\n",
        "        fig = figure(figsize=figsize)\n",
        "        ax = gca()\n",
        "    x = series.index\n",
        "    y = series.values\n",
        "    ax.loglog(x, y, '.', **kwargs)\n",
        "    return ax\n",
        "\n",
        "def display_image_from_file(filename, verbose=False):\n",
        "    from IPython.display import Image\n",
        "    if verbose:\n",
        "        print(f\"Loading image, `{filename}` ...\")\n",
        "    display(Image(filename))\n",
        "    if verbose:\n",
        "        print(f\"... done! (Did it appear?)\")\n",
        "\n",
        "# ==== Graph / NetworkX interfacing ===== #\n",
        "\n",
        "def to_nx(edge_list):\n",
        "    from networkx import DiGraph\n",
        "    G = DiGraph()\n",
        "    G.add_weighted_edges_from(edge_list)\n",
        "    return G\n",
        "\n",
        "def graph_to_matrix(G):\n",
        "    try:\n",
        "        from networkx import to_scipy_sparse_array # Works in 3.0\n",
        "        return to_scipy_sparse_array(G)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        from networkx import to_scipy_sparse_matrix # Works in 2.5\n",
        "        return to_scipy_sparse_matrix(G)\n",
        "    except:\n",
        "        raise\n",
        "\n",
        "def graph_spy(G, style='matrix', ax=None, figsize=(6.5, 6.5), **kwargs):\n",
        "    from matplotlib.pyplot import figure, gca\n",
        "    from networkx import spring_layout, draw_networkx_nodes, draw_networkx_edges, draw_networkx_labels\n",
        "\n",
        "    if ax is None:\n",
        "        fig = figure(figsize=figsize)\n",
        "        ax = gca()\n",
        "\n",
        "    if style == 'matrix':\n",
        "        A = graph_to_matrix(G)\n",
        "        ax.spy(A, **kwargs)\n",
        "    else:\n",
        "        pos = spring_layout(G, seed=7)\n",
        "\n",
        "        # nodes\n",
        "        draw_networkx_nodes(G, pos) #, node_size=700)\n",
        "\n",
        "        # edges\n",
        "        elarge = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"weight\"] >= 0.1]\n",
        "        esmall = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"weight\"] < 0.1]\n",
        "        draw_networkx_edges(G, pos, edgelist=elarge, width=2)\n",
        "        draw_networkx_edges(G, pos, edgelist=esmall, width=0.5, alpha=0.5)\n",
        "\n",
        "        # node labels\n",
        "        draw_networkx_labels(G, pos, font_size=10, font_family=\"sans-serif\")\n",
        "        # edge weight labels\n",
        "#        edge_labels = nx.get_edge_attributes(G, \"weight\")\n",
        "#        nx.draw_networkx_edge_labels(G, pos, edge_labels)\n",
        "    return ax\n",
        "\n",
        "def detect_communities(G, seed=1_234):\n",
        "    from networkx.algorithms.community import louvain_communities\n",
        "    return louvain_communities(G, seed=seed)\n",
        "\n",
        "def random_clusters(nc, nvc, p_intra=0.5, p_inter=0.1, rng_or_seed=None, verbose=False):\n",
        "    rng = get_rng(rng_or_seed, ret_type=False)\n",
        "    n = nc * nvc\n",
        "    mv_intra = int(p_intra*nvc) + 1 # no. of intra-cluster edges per vertex\n",
        "    mv_inter = int(p_inter*n)       # no. of inter-cluster edges per vertex\n",
        "\n",
        "    if verbose:\n",
        "        print('Constructing a vertex-clustered graph with these properties:')\n",
        "        print(f'- Number of clusters: nc={nc}')\n",
        "        print(f'- Vertices per cluster: nvc={nvc}')\n",
        "        print(f'- Number of intra-cluster edges per vertex: {mv_intra} (p_intra={p_intra})')\n",
        "        print(f'- Number of inter-cluster edges per vertex: {mv_inter} (p_inter={p_inter})')\n",
        "        print(f'- RNG: {rng}')\n",
        "\n",
        "    V = set(range(n)) # `n` vertices\n",
        "    E = []\n",
        "    for c in range(nc):\n",
        "        V_c = set(range(c*nvc, (c+1)*nvc))\n",
        "        for v in V_c:\n",
        "            # Add intra-cluster edges for `v`\n",
        "            N_v = sample_iter(V_c - {v}, n=mv_intra, rng_or_seed=rng)\n",
        "            W_v = rng.random(size=len(N_v))\n",
        "            E += [(v, u, w) for u, w in zip(N_v, W_v)]\n",
        "\n",
        "            # Add inter-cluster edges for `v`\n",
        "            X_v = sample_iter(V - V_c, n=mv_inter, rng_or_seed=rng)\n",
        "            W_v = rng.random(size=len(X_v)) / 10.0 # make these edges weaker, too\n",
        "            E += [(v, u, w) for u, w in zip(X_v, W_v)]\n",
        "    return E"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_0510/main/demo-comm-vecs.png\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_0510/main/demo_ex0.db\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_0510/main/ex0.txt\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_0510/main/ex10-final.df\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_0510/main/ex5.df\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_0510/main/goodreads.db\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_0510/main/tc_0\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_0510/main/tc_10\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_0510/main/tc_5\n",
        "\n",
        "!mkdir tester_fw\n",
        "%cd tester_fw\n",
        "\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_0510/main/tester_fw/__init__.py\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_0510/main/tester_fw/test_utils.py\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_0510/main/tester_fw/testers.py\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "id": "zW5XBVxgEmSi"
      },
      "id": "zW5XBVxgEmSi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "993eb8b7",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "993eb8b7"
      },
      "source": [
        "In case it's helpful, here are the versions of Python and standard modules you are using:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5972849c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:11.460183Z",
          "start_time": "2023-03-30T22:24:11.442572Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "5972849c"
      },
      "outputs": [],
      "source": [
        "print(\"* Python version: {}\".format(sys.version.replace('\\n', ' ')))\n",
        "print(f\"* Numpy version: {np.__version__}\")\n",
        "print(f\"* pandas version: {pd.__version__}\")\n",
        "print(f\"* sqlite3 version: {db.version}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdbd16b8",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "cdbd16b8"
      },
      "source": [
        "## pandas versus SQL ##\n",
        "\n",
        "The actual Goodreads data is provided via a SQLite3 database. However, only some exercises _require_ SQL; most exercises were designed with pandas in mind.\n",
        "\n",
        "Nevertheless, even some of the pandas exercises can be solved using SQL. The cell below defines the function, `dfs_to_conn`, which can be used to create in-memory database connections. If you pass in a dictionary mapping table names to pandas `DataFrame` objects, then `dfs_to_conn` will return a `sqlite3` connection with all of the data in the `DataFrame` objects available under the names given as keys. You are also free to write to the in-memory database by creating tables, inserting, deleting, updating records, etc. Anything that SQLite3 allows should work."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e45da6d8",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "e45da6d8"
      },
      "source": [
        "**Example:**\n",
        "\n",
        "```python\n",
        "    my_df = pd.DataFrame({'A':[1,2,3], 'B': [4,5,6], 'C':['x', 'y', 'z']})\n",
        "    print(my_df)\n",
        "    #    A  B  C\n",
        "    # 0  1  4  x\n",
        "    # 1  2  5  y\n",
        "    # 2  3  6  z\n",
        "    conn = dfs_to_conn({'my_table': my_df})\n",
        "    cur = conn.cursor()\n",
        "    cur.execute('select A, B, C from my_table')\n",
        "    result = cur.fetchall()\n",
        "    conn.close()\n",
        "    print(result) # list of tuples, each tuple is a row\n",
        "    #[(1, 4, 'x'), (2, 5, 'y'), (3, 6, 'z')]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da4f3479",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:11.482085Z",
          "start_time": "2023-03-30T22:24:11.463647Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "da4f3479"
      },
      "outputs": [],
      "source": [
        "def dfs_to_conn(conn_dfs, index=False):\n",
        "    import sqlite3\n",
        "    conn = sqlite3.connect(':memory:')\n",
        "    for table_name, df in conn_dfs.items():\n",
        "        df.to_sql(table_name, conn, if_exists='replace', index=index)\n",
        "    return conn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "149f9cbe",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "149f9cbe"
      },
      "source": [
        "# Goodreads Data (`grdbconn`) #"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2226954c",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "2226954c"
      },
      "source": [
        "Some of the Goodreads data is stored in a SQLite3 database. The code cell below opens a read-only connection to it named **`grdbconn`**.\n",
        "\n",
        "For now, don't worry about what's there. We will explain any tables you need in the exercises that use them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98bfb68c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:11.501956Z",
          "start_time": "2023-03-30T22:24:11.483569Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "98bfb68c"
      },
      "outputs": [],
      "source": [
        "# Goodreads database connection:\n",
        "grdbconn = db.connect('file:goodreads.db?mode=ro', uri=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "182bf3bf",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "182bf3bf"
      },
      "source": [
        "# Part A: Analyzing user-book interactions #\n",
        "\n",
        "> Includes Exercise 0 (2 points) and Exercise 1 (1 point)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d3a8864",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "7d3a8864"
      },
      "source": [
        "The Goodreads dataset includes **user-book interactions.** An \"user-book interaction\" means the user \"did something\" with the book on the Goodreads website:\n",
        "\n",
        "- _Viewed_: The user looked at a book description and saved it to their personal library.\n",
        "- _Read_: The user marked the book as \"read.\"\n",
        "- _Rated_: The user gave the book a rating, from 1 to 5 stars.\n",
        "- _Reviewed_: The user wrote a public review of the book on the website."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb68392b",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "cb68392b"
      },
      "source": [
        "These interactions are recorded in a SQL table called `Interactions`. Let's have a quick look for one of the users whose integer ID is `840218`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7883e954",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:11.555813Z",
          "start_time": "2023-03-30T22:24:11.503006Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "7883e954"
      },
      "outputs": [],
      "source": [
        "pd.read_sql(r\"SELECT * FROM Interactions WHERE user_id=830690\", grdbconn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be335380",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "be335380"
      },
      "source": [
        "Each row shows how this user interacted with some book. This user interacted with five books. However, they saved books `15396` (row 0) and `39407` (row 4) but did nothing else with themâ€”that is, they did not read them, rate them, or review them.\n",
        "\n",
        "They did rate books `19990`, giving it `5` stars, as well as `19989`, giving it `3` stars. They also read `19988`, but they did not rate it. They did not review any book (`is_reviewed=0`). Had they done so, `is_reviewed` would be `1`. All values are integers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34c1d1d9",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "tags": [
          "exercise_text"
        ],
        "id": "34c1d1d9"
      },
      "source": [
        "## **Ex. 0 (2 pts)**: `summarize_interactions_str` ##\n",
        "\n",
        "You are asked to write a summary report of the overall interactions. Complete the function\n",
        "```python\n",
        "def summarize_interactions_str(conn):\n",
        "    ...\n",
        "```\n",
        "so that it does the following.\n",
        "\n",
        "**Inputs:** The input is a SQLite3 database connection containing a table named `Interactions` with the fields `user_id`, `book_id`, `is_read`, `rating`, and `is_reviewed`, all containing integer values.\n",
        "\n",
        "**Your task:** Calculate the following:\n",
        "\n",
        "- The total number of interactions\n",
        "- The number of _unique_ user IDs\n",
        "- The number of _unique_ book IDs\n",
        "- The number of interactions where the user ...\n",
        "  - read the book, i.e., where `is_read` equals `1`;\n",
        "  - rated the book, i.e., where `rating` is _greater than_ `0`;\n",
        "  - reviewed the book, i.e., where `is_review` equals `1`.\n",
        "\n",
        "**Output:** Generate and **return a string** that reports these results. The string should be formatted as follows:\n",
        "```\n",
        "There are 370,818 interactions.\n",
        "- Unique users: 2,000\n",
        "- Unique books: 138,633\n",
        "- Number of reads: 208,701 (56.3% of all interactions)\n",
        "- Number of ratings: 194,243 (52.4%)\n",
        "- Number of reviews: 23,720 (6.4%)\n",
        "```\n",
        "In particular:\n",
        "- Commas should be used every three digits to make the numbers more readable.\n",
        "- The percentages should be reported to one digit after the decimal place (even if that digit is `0`, e.g., `37.0%`).\n",
        "- Newlines should appear between lines as shown in the example. However, there should be _no_ leading or trailing whitespace.\n",
        "\n",
        "**Additional notes and hints:**\n",
        "1. The function predefines a string template for the report. It's probably easiest to **modify** this template to achieve the desired result.\n",
        "2. You may assume that there are no duplicate (`user_id`, `book_id`) pairs.\n",
        "3. Recall that Python f-strings can help format numbers. See the demo cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faf1adbc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:11.573787Z",
          "start_time": "2023-03-30T22:24:11.556746Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "faf1adbc"
      },
      "outputs": [],
      "source": [
        "### Demo: Recall Python's f-strings\n",
        "\n",
        "print(f\"`pi` to 2 decimal digits: `{3.14159265358979:0.2f}`\")\n",
        "print(f\"Behold: `{1234567890:,}` -- neat!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd0a9652",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:11.594447Z",
          "start_time": "2023-03-30T22:24:11.574690Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "tags": [
          "demo_data"
        ],
        "id": "bd0a9652"
      },
      "outputs": [],
      "source": [
        "### Define demo inputs\n",
        "\n",
        "demo_conn_ex0 = db.connect(f'file:demo_ex0.db?mode=ro', uri=True)\n",
        "print(\"First five rows of the demo database:\")\n",
        "pd.read_sql(r\"SELECT * FROM Interactions LIMIT 5\", demo_conn_ex0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30278756",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "tags": [
          "demo_output_md"
        ],
        "id": "30278756"
      },
      "source": [
        "The demo included in the solution cell below should display the following output:\n",
        "```\n",
        "There are 12,345 interactions.\n",
        "- Unique users: 1,766\n",
        "- Unique books: 9,348\n",
        "- Number of reads: 6,844 (55.4% of all interactions)\n",
        "- Number of ratings: 6,389 (51.8%)\n",
        "- Number of reviews: 744 (6.0%)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c441ff5f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:11.657103Z",
          "start_time": "2023-03-30T22:24:11.595539Z"
        },
        "tags": [
          "exercise_solution"
        ],
        "id": "c441ff5f"
      },
      "outputs": [],
      "source": [
        "### Exercise 0 solution ###\n",
        "def summarize_interactions_str(conn):\n",
        "    # Use or adapt this template as you see fit:\n",
        "    template = \"\"\"There are {} interactions.\n",
        "- Unique users: {}\n",
        "- Unique books: {}\n",
        "- Number of reads: {} ({}% of all interactions)\n",
        "- Number of ratings: {} ({}%)\n",
        "- Number of reviews: {} ({}%)\"\"\"\n",
        "\n",
        "    ### BEGIN SOLUTION\n",
        "    df = pd.read_sql(\"SELECT * FROM Interactions\", conn)\n",
        "    n_users = len(df['user_id'].unique())\n",
        "    n_books = len(df['book_id'].unique())\n",
        "    n_reads = df['is_read'].sum()\n",
        "    n_rated = (df['rating'] > 0).sum()\n",
        "    print(df['rating'] > 0)\n",
        "    n_rev = df['is_reviewed'].sum()\n",
        "    template = f\"\"\"There are {len(df):,} interactions.\n",
        "- Unique users: {n_users:,}\n",
        "- Unique books: {n_books:,}\n",
        "- Number of reads: {n_reads:,} ({n_reads/len(df)*100:.1f}% of all interactions)\n",
        "- Number of ratings: {n_rated:,} ({n_rated/len(df)*100:.1f}%)\n",
        "- Number of reviews: {n_rev:,} ({n_rev/len(df)*100:.1f}%)\"\"\"\n",
        "    return template\n",
        "    ### END SOLUTION\n",
        "\n",
        "### demo function call\n",
        "print(summarize_interactions_str(demo_conn_ex0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2124dac",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "tags": [
          "test_data_boilerplate"
        ],
        "id": "a2124dac"
      },
      "source": [
        "<!-- Test Cell Boilerplate -->\n",
        "The cell below will test your solution for Exercise 0. The testing variables will be available for debugging under the following names in a dictionary format.\n",
        "- `input_vars` - Input variables for your solution.\n",
        "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
        "- `returned_output_vars` - Outputs returned by your solution.\n",
        "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eca2eda",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:20.200194Z",
          "start_time": "2023-03-30T22:24:19.730749Z"
        },
        "nbgrader": {
          "grade": true,
          "grade_id": "ex0",
          "locked": true,
          "points": "2",
          "solution": false
        },
        "tags": [],
        "id": "4eca2eda"
      },
      "outputs": [],
      "source": [
        "### test_cell_ex0\n",
        "from tester_fw.testers import Tester\n",
        "\n",
        "conf = {\n",
        "    'case_file':'tc_0',\n",
        "    'func': summarize_interactions_str, # replace this with the function defined above\n",
        "    'inputs':{ # input config dict. keys are parameter names\n",
        "        'conn':{\n",
        "            'dtype': 'db', # data type of param.\n",
        "            'check_modified': False,\n",
        "        }\n",
        "    },\n",
        "    'outputs':{\n",
        "        'output_0': {\n",
        "            'index': 0,\n",
        "            'dtype': 'str',\n",
        "            'check_dtype': True,\n",
        "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
        "            'check_col_order': True, # Ignored if dtype is not df\n",
        "            'check_row_order': True, # Ignored if dtype is not df\n",
        "            'check_column_type': True, # Ignored if dtype is not df\n",
        "            'float_tolerance': 10 ** (-6)\n",
        "        }\n",
        "    }\n",
        "}\n",
        "tester = Tester(conf, key=b'jpS7W-CpqAQfuITMEQZL-yVXfhIaCkSaei-emnyRtrI=', path='')\n",
        "for _ in range(10):\n",
        "    try:\n",
        "        tester.run_test()\n",
        "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
        "    except:\n",
        "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
        "        raise\n",
        "\n",
        "print('Passed! Please submit.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dee26d54",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "dee26d54"
      },
      "source": [
        "**RUN ME:** A correct implementation of `summarize_interactions_str`, when run on the full Goodreads dataset, would produce the following report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "757f69f9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:20.221162Z",
          "start_time": "2023-03-30T22:24:20.201178Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "757f69f9"
      },
      "outputs": [],
      "source": [
        "print(f\"\\n=== Report on the full dataset ===\\n\\n{load_text_from_file('ex0.txt')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc782cb9",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "tags": [
          "exercise_text"
        ],
        "id": "fc782cb9"
      },
      "source": [
        "## **Ex. 5 (2 pts)**: `connect_users` ##\n",
        "\n",
        "Given the analysis sample from Exercise 4, let's \"connect\" users.\n",
        "\n",
        "Let's say that two users `a` and `b` are **connected** if they both gave ratings of 4 or higher to the same book. The number of unique books they both rated this way is a measure of how strong their connection is.\n",
        "\n",
        "Complete the following function to help identify these connections.\n",
        "```python\n",
        "def connect_users(ubdf, threshold):\n",
        "    ...\n",
        "```\n",
        "\n",
        "**Inputs:**\n",
        "- `ubdf`: A \"user-book\" dataframe having these two columns: `user_id` and `book_id`. Each row indicates that a given user gave a given book a rating of 4 or higher.\n",
        "- `threshold`: An integer threshold on connection strength.\n",
        "\n",
        "**Your tasks:** Determine which pairs of users are connected. Count how many books connect them. Drop self-pairs (`user_id_x == user_id_y`), as well as any pairs with fewer than `threshold` connections.\n",
        "\n",
        "**Outputs:** Return a **new** `DataFrame` with three columns:\n",
        "1. `user_id_x`: A user ID\n",
        "2. `user_id_y`: Another user ID\n",
        "3. `count`: The number of books they both rated in common. Recall that this value should be `>= threshold`.\n",
        "\n",
        "**Additional notes and hints.**\n",
        "1. Omit self-pairs, that is, cases where `user_id_x` == `user_id_y`.\n",
        "1. Return pairs **symmetrically**. That is, if the pair of users (`a`, `b`) have a count `k` at or above the threshold, then **both** (`a`, `b`, `k`) and (`b`, `a`, `k`) should be rows in the output table.\n",
        "1. If no connections meet the threshold, you should return an empty `DataFrame` _with_ the specified columns.\n",
        "1. You may assume there are no duplicate rows.\n",
        "\n",
        "> _Aside:_ For really huge datasets (not what is included in this exam), dropping users with fewer than `threshold` ratings _before_ looking for pairs might be a bit faster.\n",
        "\n",
        "**Example:** Suppose the inputs are the `DataFrame` shown below with a target connection threshold of `2`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46c2bf1d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:23.419334Z",
          "start_time": "2023-03-30T22:24:23.395269Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "tags": [
          "demo_data"
        ],
        "id": "46c2bf1d"
      },
      "outputs": [],
      "source": [
        "### Define demo inputs ###\n",
        "\n",
        "demo_ubdf_ex5 = load_df_from_file(\"demo_ex5.df\").sort_values(['book_id', 'user_id']).reset_index(drop=True)\n",
        "demo_threshold_ex5 = 2\n",
        "\n",
        "display(demo_ubdf_ex5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5da9842",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "tags": [
          "demo_output_md"
        ],
        "id": "b5da9842"
      },
      "source": [
        "For this input, `connect_users` should produce:\n",
        "\n",
        "|   user_id_x |   user_id_y |   count |\n",
        "|------------:|------------:|--------:|\n",
        "|           0 |           2 |       2 |\n",
        "|           0 |           3 |       2 |\n",
        "|           2 |           0 |       2 |\n",
        "|           3 |           0 |       2 |\n",
        "\n",
        "Users `0` and `2` both rated books `7` and `19`, so they meet the threshold of having reviewed 2 books in common. User `1` did not review any books in common with any other user, and so they do not appear in any pair of the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e3ff577",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:23.447658Z",
          "start_time": "2023-03-30T22:24:23.420393Z"
        },
        "tags": [
          "exercise_solution"
        ],
        "id": "4e3ff577"
      },
      "outputs": [],
      "source": [
        "### Exercise 5 solution\n",
        "def connect_users(ubdf, threshold):\n",
        "    ### BEGIN SOLUTION\n",
        "    uudf = ubdf.merge(ubdf, on='book_id') \\\n",
        "               .groupby(['user_id_x', 'user_id_y']) \\\n",
        "               .size() \\\n",
        "               .reset_index() \\\n",
        "               .rename(columns={0: 'count'})\n",
        "    uudf = uudf[uudf['user_id_x'] != uudf['user_id_y']]\n",
        "    uudf = uudf[uudf['count'] >= threshold]\n",
        "    uudf = uudf.reset_index(drop=True)\n",
        "    return uudf\n",
        "    ### END SOLUTION\n",
        "\n",
        "### demo function call ###\n",
        "connect_users(demo_ubdf_ex5, demo_threshold_ex5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f8c7fa4",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "tags": [
          "test_data_boilerplate"
        ],
        "id": "5f8c7fa4"
      },
      "source": [
        "<!-- Test Cell Boilerplate -->\n",
        "The cell below will test your solution for Exercise 5. The testing variables will be available for debugging under the following names in a dictionary format.\n",
        "- `input_vars` - Input variables for your solution.\n",
        "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
        "- `returned_output_vars` - Outputs returned by your solution.\n",
        "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6052eef5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:24.465383Z",
          "start_time": "2023-03-30T22:24:24.115914Z"
        },
        "nbgrader": {
          "grade": true,
          "grade_id": "ex5",
          "locked": true,
          "points": "2",
          "solution": false
        },
        "tags": [],
        "id": "6052eef5"
      },
      "outputs": [],
      "source": [
        "### test_cell_ex5\n",
        "from tester_fw.testers import Tester\n",
        "\n",
        "conf = {\n",
        "    'case_file':'tc_5',\n",
        "    'func': connect_users, # replace this with the function defined above\n",
        "    'inputs':{ # input config dict. keys are parameter names\n",
        "        'ubdf': {\n",
        "            'dtype': 'df', # data type of param.\n",
        "            'check_modified': True\n",
        "        },\n",
        "        'threshold': {\n",
        "            'dtype': 'int',\n",
        "            'check_modified': False\n",
        "        }\n",
        "    },\n",
        "    'outputs':{\n",
        "        'output_0':{\n",
        "            'index': 0,\n",
        "            'dtype': 'df',\n",
        "            'check_dtype': True,\n",
        "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
        "            'check_col_order': False, # Ignored if dtype is not df\n",
        "            'check_row_order': False, # Ignored if dtype is not df\n",
        "            'float_tolerance': 10 ** (-6)\n",
        "        }\n",
        "    }\n",
        "}\n",
        "tester = Tester(conf, key=b'jpS7W-CpqAQfuITMEQZL-yVXfhIaCkSaei-emnyRtrI=', path='')\n",
        "for _ in range(70):\n",
        "    try:\n",
        "        tester.run_test()\n",
        "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
        "    except:\n",
        "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
        "        raise\n",
        "\n",
        "print('Passed! Please submit.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adc6ef9f",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "adc6ef9f"
      },
      "source": [
        "**RUN ME:** From a correct implementation of `connect_users`, one way we can \"draw\" the connectivity is to form a sparse matrix where nonzeros represent connections. Here is a picture of this matrix for the full dataset, using a threshold of 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d8853f9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:24.510867Z",
          "start_time": "2023-03-30T22:24:24.466460Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "2d8853f9"
      },
      "outputs": [],
      "source": [
        "uudf = load_df_from_file('ex5.df') # user-user table\n",
        "\n",
        "print(\"A sample of connections:\")\n",
        "display(uudf.head())\n",
        "\n",
        "if False: # Disabled due to NetworkX version incompatibility issue (fix pending)\n",
        "    uudf_G = cse6040.utils.to_nx(uudf.to_records(index=False))\n",
        "    ax_ex5 = cse6040.utils.graph_spy(uudf_G, markersize=0.01)\n",
        "    ax_ex5.set_title('Spy plot: user-user interactions')\n",
        "    ax_ex5.set_xlabel('user id')\n",
        "    ax_ex5.set_ylabel('user id', rotation=0, horizontalalignment='right');\n",
        "else:\n",
        "#     cse6040.utils.display_image_from_file('demo-user-user-spy.png')\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5bb0f04",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "c5bb0f04"
      },
      "source": [
        "> **Aside (skip if pressed for time):** The \"grid-like\" pattern you might see suggests that there are groups or clusters of interconnected users in the data. Our next task will try to identify them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef0b2698",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "ef0b2698"
      },
      "source": [
        "# Part F (final part!): Merging inventory metadata #\n",
        "\n",
        "> Includes Exercises 9 and 10 (2 points each).\n",
        "\n",
        "\n",
        "To interpret the communities, we need to bring in some book-inventory metadata, like book titles and genres. Once we've done so, will the communities make sense?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc12f38b",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "cc12f38b"
      },
      "source": [
        "## Genre vectors ##\n",
        "\n",
        "The original dataset includes information on _genres_ for each book:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5567810",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:33.895548Z",
          "start_time": "2023-03-30T22:24:33.725382Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "e5567810"
      },
      "outputs": [],
      "source": [
        "genres = pd.read_sql(\"SELECT * FROM Genres\", grdbconn)\n",
        "genres"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "562325d7",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "562325d7"
      },
      "source": [
        "It's a bit messy, however: the genre information is stored as a JSON-formatted Python string encoding a **genre vector**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "672e3717",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:33.918656Z",
          "start_time": "2023-03-30T22:24:33.897585Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "672e3717"
      },
      "outputs": [],
      "source": [
        "# Inspect the very first genre entry:\n",
        "print(f\"* Type: `{type(genres['genres'].iloc[0])}`\")\n",
        "print(f\"* Value: '{genres['genres'].iloc[0]}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8b160cd",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "c8b160cd"
      },
      "source": [
        "This genre vector says that this particular book mixes three genres: `fiction`, `romance`, and `\"mystery, thriller, crime\"` (considered a single genre). Each value measures the relevance of that genre to the book.\n",
        "\n",
        "> Roughly speaking, let's interpret `555` as meaning this book is 555 / (555+23+10) ~ 94.3% \"fiction\" and 23 / (555+23+10) ~ 3.9% \"romance.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81d77913",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "81d77913"
      },
      "source": [
        "The database stores these as genre vectors as strings. However, we can easily convert them to Python dictionaries using the following helper function, `from_json_str`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "039cdf99",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:33.941367Z",
          "start_time": "2023-03-30T22:24:33.919682Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "039cdf99"
      },
      "outputs": [],
      "source": [
        "def from_json_str(s):\n",
        "    \"\"\"Parses the JSON string `s` and returns a Python object.\"\"\"\n",
        "    from json import loads\n",
        "    return loads(s)\n",
        "\n",
        "\n",
        "# Demo #\n",
        "\n",
        "print(\"iloc 0:\", from_json_str(genres['genres'].iloc[0]))\n",
        "print(\"iloc 1:\", from_json_str(genres['genres'].iloc[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b194a25",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "6b194a25"
      },
      "source": [
        "We will treat these as (mathematical) vectors that we can \"add.\" Here is a simple function to compute the sum of two genre vectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f74c1e15",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:33.966242Z",
          "start_time": "2023-03-30T22:24:33.942527Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "f74c1e15"
      },
      "outputs": [],
      "source": [
        "def add_genre_vecs(x, y):\n",
        "    \"\"\"Returns the sum of two genre vectors.\"\"\"\n",
        "    from collections import defaultdict\n",
        "    z = defaultdict(int)\n",
        "    for k, v in x.items():\n",
        "        z[k] += v\n",
        "    for k, v in y.items():\n",
        "        z[k] += v\n",
        "    return dict(z) # Converts into a regular Python dict\n",
        "\n",
        "# Demo: start with two genre vectors, converted to `dict`:\n",
        "demo_genre_vec_a = from_json_str(genres['genres'].iloc[0])\n",
        "demo_genre_vec_b = from_json_str(genres['genres'].iloc[1])\n",
        "\n",
        "# Add them:\n",
        "add_genre_vecs(demo_genre_vec_a, demo_genre_vec_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6abc8a47",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "tags": [
          "exercise_text"
        ],
        "id": "6abc8a47"
      },
      "source": [
        "## **Ex. 10 (2 pts)**: `combine_all_data` ##\n",
        "\n",
        "The final step in our analysis is to combine several pieces of information into a final `DataFrame`. In particular, we'd like to take the \"top reads\" results from Exercise 8 and add in (a) book titles and (b) book genres. Complete the function so that it carries out this task.\n",
        "\n",
        "```python\n",
        "def combine_all_data(topdf, book2inv, invdf, genresdf):\n",
        "    ...\n",
        "```\n",
        "\n",
        "**Inputs:** The inputs consist of **four** `DataFrame` objects.\n",
        "- **`topdf`**: A dataframe of the top reads by community (e.g., from Ex. 8). Its columns are:\n",
        "  * `'comm_id'`: An integer community ID\n",
        "  * `'book_id'`: An integer book ID\n",
        "  * `'comm_size'`: The number of users in the community\n",
        "  * `'percent'`: The percentage of community users that read the given book\n",
        "- **`book2inv`**: A dataframe to convert book IDs into _\"inventory IDs.\"_ It has two columns:\n",
        "  * `'book_id'`: An integer book ID\n",
        "  * `'inv_id'`: An inventory ID, which can be used to link the book to its title and genre\n",
        "- **`invdf`**: An inventory of books. Its columns include:\n",
        "  * `'inv_id'`: An integer inventory ID\n",
        "  * `'title'`: The book's title, a string\n",
        "  * `'description'`: A brief description of the book\n",
        "- **`genres`**: Genre vectors, encoded as JSON strings. Its columns are:\n",
        "  * `'inv_id'`: The integer inventory ID\n",
        "  * `'genres'`: The genre vector (as a JSON string)\n",
        "\n",
        "**Your task:** Merge all of this data into a single `DataFrame`. You should perform a series of left-merges (pandas equivalent of left-joins), starting with `topdf`, using either `book_id` or `inv_id` to link the dataframes. By doing left-joins, you will preserve all the rows of `topdf`.\n",
        "\n",
        "**Outputs:** Your function should return the `DataFrame`. It will have only the columns listed above: `'comm_id'`, `'book_id'`, `'comm_size'`, `'percent'`, `'inv_id'`, `'title'`, `'description'`, `'genres'`.\n",
        "\n",
        "**Additional notes:** You do not need to convert any of the fields, you just need to arrange the merges correctly.\n",
        "\n",
        "**Example:** The following cell loads some demo inputs that you can use for testing and debugging. (Because there are several of these, we have refrained from printing them. However, you can use the next cell to write code to explore them.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a64b867e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:34.315311Z",
          "start_time": "2023-03-30T22:24:34.292931Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "tags": [
          "demo_data"
        ],
        "id": "a64b867e"
      },
      "outputs": [],
      "source": [
        "### Define demo inputs ###\n",
        "\n",
        "demo_topdf_ex10 = load_df_from_file(\"demo_ex10-topdf.df\")\n",
        "demo_book2inv_ex10 = load_df_from_file(\"demo_ex10-book2inv.df\")\n",
        "demo_invdf_ex10 = load_df_from_file(\"demo_ex10-invdf.df\")\n",
        "demo_genresdf_ex10 = load_df_from_file(\"demo_ex10-genresdf.df\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ee13ade",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:34.336344Z",
          "start_time": "2023-03-30T22:24:34.316301Z"
        },
        "id": "1ee13ade"
      },
      "outputs": [],
      "source": [
        "# Use this cell to `display`, `print`, or otherwise explore those demo inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17a2880d",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "tags": [
          "demo_output_md"
        ],
        "id": "17a2880d"
      },
      "source": [
        "A correctly functioning `combine_all_data` will produce the following output on the demo inputs:\n",
        "\n",
        "|   comm_id |   book_id |   comm_size |   percent |   inv_id | title                                                       | description   | genres                                                                                                                     |\n",
        "|----------:|----------:|------------:|----------:|---------:|:------------------------------------------------------------|:--------------|:---------------------------------------------------------------------------------------------------------------------------|\n",
        "|         0 |       821 |         868 |   22.5806 |     5470 | 1984                                                        | The year 1... | {\"fiction\": 25686, \"fantasy, paranormal\": 1776, \"young-adult\": 233}                                                        |\n",
        "|         0 |       943 |         868 |   21.4286 |        3 | Harry Potter and the Sorcerer's Stone (Harry Potter, #1)    | Harry Pott... | {\"fantasy, paranormal\": 54156, \"young-adult\": 17058, \"fiction\": 15016, \"children\": 11213, \"mystery, thriller, crime\": 668} |\n",
        "|         2 |     49734 |          36 |   22.2222 |  6604887 | Ø£Ù†Øª Ù„ÙŠ                                                      |               | {\"romance\": 31, \"fiction\": 9}                                                                                              |\n",
        "|         2 |     23164 |          36 |   19.4444 |  7704143 | ØªØ±Ø§Ø¨ Ø§Ù„Ù…Ø§Ø³                                                  | \"llmr@ lth... | {\"fiction\": 27, \"mystery, thriller, crime\": 32}                                                                            |\n",
        "|         3 |       943 |         340 |   77.0588 |        3 | Harry Potter and the Sorcerer's Stone (Harry Potter, #1)    | Harry Pott... | {\"fantasy, paranormal\": 54156, \"young-adult\": 17058, \"fiction\": 15016, \"children\": 11213, \"mystery, thriller, crime\": 668} |\n",
        "|         3 |       941 |         340 |   74.1176 |        5 | Harry Potter and the Prisoner of Azkaban (Harry Potter, #3) | Harry Pott... | {\"fiction\": 12103, \"children\": 8558, \"fantasy, paranormal\": 4639, \"young-adult\": 1513, \"mystery, thriller, crime\": 537}    |\n",
        "|         4 |    139433 |           6 |   50      |   148849 | Ø´Ø§Ø²Ø¯Ù‡ Ú©ÙˆÚ†ÙˆÙ„Ùˆ                                                | shzdh khwc... | {\"fiction\": 5481, \"fantasy, paranormal\": 3847, \"children\": 8886, \"young-adult\": 1127}                                      |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f2dd72",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:34.365580Z",
          "start_time": "2023-03-30T22:24:34.337232Z"
        },
        "tags": [
          "exercise_solution"
        ],
        "id": "a0f2dd72"
      },
      "outputs": [],
      "source": [
        "### Exercise 10 solution\n",
        "def combine_all_data(topdf, book2inv, invdf, genresdf):\n",
        "    ### BEGIN SOLUTION\n",
        "    return topdf[['comm_id', 'book_id', 'comm_size', 'percent']] \\\n",
        "            .merge(book2inv[['book_id', 'inv_id']], on='book_id', how='left') \\\n",
        "            .merge(invdf[['inv_id', 'title', 'description']], on='inv_id', how='left') \\\n",
        "            .merge(genresdf, on='inv_id', how='left') \\\n",
        "            .sort_values(['comm_id', 'percent'], ascending=[True, False])\n",
        "    ### END SOLUTION\n",
        "\n",
        "### demo function call ###\n",
        "# combine_all_data(demo_topdf_ex10, demo_book2inv_ex10, demo_invdf_ex10, demo_genresdf_ex10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9175f09",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "tags": [
          "test_data_boilerplate"
        ],
        "id": "b9175f09"
      },
      "source": [
        "<!-- Test Cell Boilerplate -->\n",
        "The cell below will test your solution for Exercise 10. The testing variables will be available for debugging under the following names in a dictionary format.\n",
        "- `input_vars` - Input variables for your solution.\n",
        "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
        "- `returned_output_vars` - Outputs returned by your solution.\n",
        "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "384b5f0e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:41.906350Z",
          "start_time": "2023-03-30T22:24:41.097923Z"
        },
        "nbgrader": {
          "grade": true,
          "grade_id": "ex10",
          "locked": true,
          "points": "2",
          "solution": false
        },
        "tags": [],
        "id": "384b5f0e"
      },
      "outputs": [],
      "source": [
        "### test_cell_ex10\n",
        "from tester_fw.testers import Tester\n",
        "\n",
        "conf = {\n",
        "    'case_file': 'tc_10',\n",
        "    'func': combine_all_data, # replace this with the function defined above\n",
        "    'inputs': { # input config dict. keys are parameter names\n",
        "        'topdf': {'dtype': 'df', 'check_modified': True},\n",
        "        'book2inv': {'dtype': 'df', 'check_modified': True},\n",
        "        'invdf': {'dtype': 'df', 'check_modified': True},\n",
        "        'genresdf': {'dtype': 'df', 'check_modified': True},\n",
        "    },\n",
        "    'outputs': {\n",
        "        'output_0': {\n",
        "            'index': 0,\n",
        "            'dtype': 'df',\n",
        "            'check_dtype': True,\n",
        "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
        "            'check_col_order': False, # Ignored if dtype is not df\n",
        "            'check_row_order': False, # Ignored if dtype is not df\n",
        "            'float_tolerance': 10 ** (-6)\n",
        "        }\n",
        "    }\n",
        "}\n",
        "tester = Tester(conf, key=b'jpS7W-CpqAQfuITMEQZL-yVXfhIaCkSaei-emnyRtrI=', path='')\n",
        "for _ in range(70):\n",
        "    try:\n",
        "        tester.run_test()\n",
        "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
        "    except:\n",
        "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
        "        raise\n",
        "\n",
        "print('Passed! Please submit.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6696e89b",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "6696e89b"
      },
      "source": [
        "**RUN ME:** If `combine_all_data` is working and applied to the full Goodreads dataset, here are the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3a40614",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:41.945581Z",
          "start_time": "2023-03-30T22:24:41.907329Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "f3a40614"
      },
      "outputs": [],
      "source": [
        "ex10_final = load_df_from_file('ex10-final.df')\n",
        "ex10_final_groups = ex10_final.groupby('comm_id')\n",
        "for comm_id in ex10_final_groups.groups.keys():\n",
        "    display(ex10_final_groups.get_group(comm_id))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01281517",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "01281517"
      },
      "source": [
        "> Scan the titles, descriptions, and genres. Do the community labels appear to identify distinct communities?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "575ff5d8",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "tags": [
          "fin"
        ],
        "id": "575ff5d8"
      },
      "source": [
        "# Fin! #\n",
        "\n",
        "If you have made it this far, that's it â€” congratulations on completing the exam. **Don't forget to submit!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d05fd74c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-30T22:24:41.967853Z",
          "start_time": "2023-03-30T22:24:41.946674Z"
        },
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "d05fd74c"
      },
      "outputs": [],
      "source": [
        "# Close database connection\n",
        "try:\n",
        "    grdbconn.close()\n",
        "except:\n",
        "    print(\"Goodreads database-connection may already be closed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a05247ca",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "a05247ca"
      },
      "source": [
        "**Postscript.** Had you gotten everything right, then we could have performed one final analysis on the previous result.\n",
        "\n",
        "Suppose you calculate the normalized genre vectors for each community, and then plot the components for each community as shown below.\n",
        "\n",
        "![Genre vectors uncovered](https://github.com/gt-cse-6040/topic_07_MT2_SP23_0510/blob/main/demo-comm-vecs.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dc2ae71",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "9dc2ae71"
      },
      "source": [
        "Darker bars correspond to more highly weighted components. You can see that the community genre-vectors are distinct from one another, albeit with some (expected) overlaps. Thus, there is, arguably, at least some additional evidence to suspect this initial grouping may be a meaningful one for helping users find other users and appropriate book recommendations. The analysis in this notebook operated on just a small fraction of the complete dataset, and it is possible that with more data more distinct communities could emerge."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f031ba9",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "9f031ba9"
      },
      "source": [
        "**Want to explore this dataset on your own?** Refer to the [Goodreads Dataset](https://sites.google.com/eng.ucsd.edu/ucsdbookgraph/home). It was originally collected in 2017 by researchers at the University of California, San Diego. It is quite extensive, and what we did in this exam barely scratches the surface of what is possible!"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "f2b38b6e01547e8f771d473ea2b8718fd0728eea782e4c924ed8783f739d4a6c"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "292.8px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}